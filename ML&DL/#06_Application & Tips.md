Machine Learning & Deep Learning
===================================
Application & Tips
------------------------------------

### CONTENTS
* [Learning rate를 적절히 조절해야하는 이유](#learning-rate를-적절히-조절해야하는-이유)
* [데이터의 전처리가 필요한 이유](#데이터의-전처리가-필요한-이유)
* [오버피팅을 적절히 해야하는 이유](#오버피팅을-적절히-해야하는-이유)
* [모든 데이터를 학습시키면 안되는 이유](#모든-데이터를-학습시키면-안되는-이유)



### Reference
* [Youtube - 모두를 위한 딥러닝 강좌 시즌1](https://www.youtube.com/watch?v=BS6O0zOGX4E&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=1)

### Learning rate를 적절히 조절해야하는 이유
* Learning rate가 큰 경우
  * 최소 cost를 찾기 못하고 발산하는 경우가 발생한다
  * cost함수값이 불규칙하게 변하면 learning rate를 낮춰준다
* Learning rate가 작은 경우
  * 시간이 오래걸리고 최저점이 아닌데도 stop하는 경우가 발생한다
  * cost함수를 출력해봤을때 변화가 거의 없을때는 살짝 높여준다
* **Learning rate를 설정하는데는 답이 없다**

### 데이터의 전처리가 필요한 이유
* Cost함수를 3d화 했을때 토기모양(등고선)의 모형을 갖게된다.
* 만약 데이터들의 분포가 불규칙하다면(차이가 큰 데이터들이 존재한다) 데이터분포가 균등하게 분포되지않게된다.
* 따라서 Normalize를 해줘야한다
* Standardization을 이용해 전처리를 수행해준다(Python코드 존재)

### 오버피팅을 적절히 해야하는 이유
* 모든 데이터에 맞춤화된 모델이 아니라 현재 있는 데이터에만 맞춤화되다보니 다른경우에서 잘 작동하지 않는 경우가 있다.
* 해결하는 방법
  * 데이터 추가
  * 중복데이터 삭제
  * Regularization -> 일반화시킨다

### 데이터 전부를 학습시키지말고, 일부데이터는 Validation, Testing에 이용한다
* 흔히 공부할때 70%만 대비하고 30%는 실전모의고사에 사용하듯이 데이터를 전부가 아닌 대다수의 데이터를 학습시켜 진행해야한다.
